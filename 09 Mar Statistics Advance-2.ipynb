{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f69aaa91-4c89-465a-86bc-74b587862bd7",
   "metadata": {},
   "source": [
    "# Q1: What are the Probability Mass Function (PMF) and Probability Density Function (PDF)? Explain with an example."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05cec095-e0d2-49a6-95e3-3ddc3b730f4a",
   "metadata": {},
   "source": [
    "Probability Mass Function (PMF) and Probability Density Function (PDF) are both mathematical functions used to describe the probability distribution of a random variable.\n",
    "\n",
    "A Probability Mass Function (PMF) is used for discrete random variables, which can only take on a finite or countably infinite number of possible values. The PMF gives the probability of each possible value of the random variable.\n",
    "\n",
    "For example, let's consider the roll of a fair six-sided die. The possible outcomes are the integers 1 through 6, and each outcome has a probability of 1/6. The PMF for this random variable can be written as:\n",
    "\n",
    "P(X = 1) = 1/6\n",
    "P(X = 2) = 1/6\n",
    "P(X = 3) = 1/6\n",
    "P(X = 4) = 1/6\n",
    "P(X = 5) = 1/6\n",
    "P(X = 6) = 1/6\n",
    "\n",
    "where X represents the outcome of the die roll.\n",
    "\n",
    "On the other hand, a Probability Density Function (PDF) is used for continuous random variables, which can take on an uncountably infinite number of possible values within a certain range. The PDF gives the probability density at each possible value of the random variable.\n",
    "\n",
    "For example, let's consider the height of adult males in a population. The height can take on any value within a certain range, and it is a continuous random variable. The PDF for this random variable can be represented using a bell-shaped curve known as the normal distribution. The PDF gives the probability density at each possible height, but not the probability of a specific height.\n",
    "\n",
    "The PDF of the normal distribution can be represented by the following formula:\n",
    "\n",
    "f(x) = (1/σ√(2π)) * e^(-(x-μ)²/(2σ²))\n",
    "\n",
    "where x represents the height, μ is the mean height, σ is the standard deviation, π is the mathematical constant pi, and e is the mathematical constant e (approximately equal to 2.71828). The value of f(x) represents the probability density at a specific height x.\n",
    "\n",
    "It is important to note that the area under the PDF curve between two values a and b represents the probability that the random variable falls between a and b."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea328735-1bf4-4e5c-9da0-6e8d0566e3bb",
   "metadata": {},
   "source": [
    "# Q2: What is Cumulative Density Function (CDF)? Explain with an example. Why CDF is used?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceaf887b-29ed-4326-9255-d840a64c6c20",
   "metadata": {},
   "source": [
    "A Cumulative Density Function (CDF) is a mathematical function that describes the cumulative probability distribution of a random variable. The CDF gives the probability that the random variable takes on a value less than or equal to a given value.\n",
    "\n",
    "For a discrete random variable, the CDF is defined as the sum of the probabilities of all values less than or equal to the given value. For a continuous random variable, the CDF is defined as the integral of the PDF up to the given value.\n",
    "\n",
    "For example, let's consider a continuous random variable X that follows the standard normal distribution (mean = 0, standard deviation = 1). The PDF of the standard normal distribution is given by the formula:\n",
    "\n",
    "f(x) = (1/√(2π)) * e^(-x²/2)\n",
    "\n",
    "The CDF of the standard normal distribution can be written as:\n",
    "\n",
    "F(x) = P(X ≤ x) = ∫(-∞, x) f(t) dt\n",
    "\n",
    "where F(x) represents the cumulative probability that X is less than or equal to x, and f(t) represents the PDF of X. The integral is taken over the entire range of possible values of X, from negative infinity to x.\n",
    "\n",
    "The CDF is a useful tool in probability and statistics because it provides a way to calculate the probability that a random variable takes on a value within a certain range. For example, the probability that a standard normal random variable is between -1 and 1 can be calculated using the CDF as:\n",
    "\n",
    "P(-1 ≤ X ≤ 1) = F(1) - F(-1)\n",
    "\n",
    "where F(1) and F(-1) are the values of the CDF at x = 1 and x = -1, respectively.\n",
    "\n",
    "In addition, the CDF can be used to calculate other important statistics, such as the median and quartiles of a distribution, and to compare different probability distributions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "861a5590-394d-45c4-a4ed-7b98f3be512b",
   "metadata": {},
   "source": [
    "# Q3: What are some examples of situations where the normal distribution might be used as a model?\n",
    "# Explain how the parameters of the normal distribution relate to the shape of the distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35b1e674-3148-449f-ac77-c0b205d648b2",
   "metadata": {},
   "source": [
    "The normal distribution is widely used as a model for many natural and human-made phenomena. Here are some examples:\n",
    "\n",
    "* Heights and weights of individuals in a population.\n",
    "* Test scores in a large student population.\n",
    "* Errors in measurements due to random fluctuations.\n",
    "* Returns on financial investments.\n",
    "* Time taken to complete a task by a group of people.\n",
    "\n",
    "The normal distribution is often used in these situations because it is a bell-shaped probability distribution that is symmetric around the mean. This means that the majority of the observations fall close to the mean, and the likelihood of observing an observation farther away from the mean decreases rapidly.\n",
    "\n",
    "The normal distribution is characterized by two parameters: the mean (μ) and the standard deviation (σ). The mean represents the central tendency of the distribution and determines the location of the peak of the bell-shaped curve. The standard deviation measures the spread or variability of the distribution, and determines the width of the bell-shaped curve.\n",
    "\n",
    "If the mean is larger, the distribution shifts to the right, while a smaller mean causes the distribution to shift to the left. If the standard deviation is larger, the curve becomes wider and flatter, while a smaller standard deviation results in a taller and narrower curve.\n",
    "\n",
    "The normal distribution is also known as the Gaussian distribution or the bell curve, and is widely used in statistical inference and hypothesis testing due to its mathematical properties and the availability of many analytical tools."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "928b7607-8483-46ed-8380-892c453ca260",
   "metadata": {},
   "source": [
    "# Q4: Explain the importance of Normal Distribution. Give a few real-life examples of Normal Distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69f8cd04-a68e-49f1-9fee-b9d60eb1d4b6",
   "metadata": {},
   "source": [
    "The normal distribution is one of the most important probability distributions in statistics, and it is widely used in many fields of study. Here are some reasons why the normal distribution is important:\n",
    "\n",
    "* Central Limit Theorem: The normal distribution plays a crucial role in the Central Limit Theorem, which states that if a sample is drawn from a population, the distribution of sample means will be approximately normal, regardless of the distribution of the population. This makes the normal distribution a fundamental tool for statistical inference.\n",
    "\n",
    "* Data Modeling: The normal distribution is often used as a model for many real-life phenomena because it approximates the behavior of many naturally occurring variables, such as heights, weights, test scores, and financial returns.\n",
    "\n",
    "* Hypothesis Testing: Many statistical tests, such as t-tests and ANOVA, assume normality of the data. Hence, the normal distribution is essential in testing statistical hypotheses and drawing conclusions from data.\n",
    "\n",
    "Here are some examples of real-life phenomena that follow a normal distribution:\n",
    "\n",
    "* The heights of individuals in a population.\n",
    "* The weights of packages in a production line.\n",
    "* The errors in measurements due to random fluctuations.\n",
    "* The IQ scores of a large student population.\n",
    "* The returns on financial investments.\n",
    "\n",
    "In all these examples, the normal distribution provides a useful model for understanding the underlying behavior of the variables and making predictions about future outcomes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1387319c-0b6a-4536-ab34-980eb0c979e7",
   "metadata": {},
   "source": [
    "# Q5: What is Bernaulli Distribution? Give an Example. What is the difference between Bernoulli Distribution and Binomial Distribution?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af55a9bc-9235-4278-81dc-846b53d25651",
   "metadata": {},
   "source": [
    "Bernoulli distribution is a discrete probability distribution that models a binary outcome, where the event can either happen (success) with probability p or not happen (failure) with probability 1-p, where p is a parameter that represents the probability of success. The Bernoulli distribution can be written as:\n",
    "\n",
    "P(X=x) = p^x (1-p)^(1-x), for x=0,1\n",
    "\n",
    "where X is a random variable that takes values 0 or 1, and p is the probability of success.\n",
    "\n",
    "A classic example of Bernoulli distribution is a coin flip, where heads is a success (p=0.5) and tails is a failure (p=0.5).\n",
    "\n",
    "The main difference between Bernoulli and Binomial distributions is that Bernoulli distribution models a single trial or experiment with binary outcomes, while the binomial distribution models a series of independent Bernoulli trials with the same probability of success, and counts the number of successes in a fixed number of trials.\n",
    "\n",
    "The binomial distribution can be defined as the sum of n independent Bernoulli trials, where each trial has probability p of success. The binomial distribution can be written as:\n",
    "\n",
    "P(X=k) = nCk * p^k * (1-p)^(n-k), for k=0,1,2,...,n\n",
    "\n",
    "where X is a random variable that represents the number of successes in n trials, p is the probability of success in each trial, and n is the number of trials.\n",
    "\n",
    "For example, the number of heads obtained in 10 coin flips can be modeled using a binomial distribution with n=10 and p=0.5.\n",
    "\n",
    "In summary, Bernoulli distribution models a single trial with binary outcomes, while the binomial distribution models a series of independent Bernoulli trials with the same probability of success, and counts the number of successes in a fixed number of trials."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5612e2a-1b86-4b9a-a41a-5e2533401b1d",
   "metadata": {},
   "source": [
    "# Q6. Consider a dataset with a mean of 50 and a standard deviation of 10. If we assume that the dataset is normally distributed, what is the probability that a randomly selected observation will be greater than 60? Use the appropriate formula and show your calculations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53777eea-31c1-43a7-89ac-d67e1c468380",
   "metadata": {},
   "source": [
    "Given the dataset has a mean of 50 and a standard deviation of 10, we can assume that it follows a normal distribution with parameters μ = 50 and σ = 10. We want to find the probability that a randomly selected observation will be greater than 60.\n",
    "\n",
    "To calculate this probability, we can use the standard normal distribution and the Z-score formula:\n",
    "\n",
    "Z = (X - μ) / σ\n",
    "\n",
    "where X is the value we want to calculate the probability for, μ is the mean of the distribution, and σ is the standard deviation of the distribution. We can standardize the value of X to get its corresponding Z-score, which can then be looked up in the standard normal distribution table to find the probability.\n",
    "\n",
    "In this case, we want to find the probability that X is greater than 60. So we first standardize the value of 60:\n",
    "\n",
    "Z = (60 - 50) / 10\n",
    "Z = 1\n",
    "\n",
    "We can then use the standard normal distribution table to find the probability that Z is greater than 1. From the table, we find that the probability that Z is greater than 1 is approximately 0.1587.\n",
    "\n",
    "Therefore, the probability that a randomly selected observation from this dataset will be greater than 60 is approximately 0.1587 or 15.87%."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "608df0a0-66ac-49d8-98dd-ea6468b1f320",
   "metadata": {},
   "source": [
    "# Q7: Explain uniform Distribution with an example."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdbbb4a7-dc85-4d30-a8ec-2b8b92199b8e",
   "metadata": {},
   "source": [
    "Uniform distribution is a continuous probability distribution that models a random variable that can take on any value in a fixed range, with each value having an equal probability of occurring. The probability density function (PDF) of the uniform distribution is constant over the entire range and zero outside it. The uniform distribution is often used as a model when there is no a priori reason to believe that any value in the range is more likely than any other value.\n",
    "\n",
    "The PDF of the uniform distribution can be written as:\n",
    "\n",
    "f(x) = 1/(b-a), for a <= x <= b\n",
    "\n",
    "where a and b are the lower and upper bounds of the range, respectively.\n",
    "\n",
    "A classic example of uniform distribution is rolling a fair die, where each of the six possible outcomes (1, 2, 3, 4, 5, and 6) has an equal probability of occurring. The probability of rolling any given number is 1/6, and the probability of rolling a number between 1 and 6 (inclusive) is 1, since there are no other possible outcomes.\n",
    "\n",
    "Another example of uniform distribution is the distribution of arrival times of customers at a store during a particular hour. If we assume that customers arrive at random times during the hour, with no particular pattern or clustering, then the arrival times can be modeled using a uniform distribution with the lower bound being the start of the hour and the upper bound being the end of the hour. Each minute during the hour has an equal probability of having a customer arrive.\n",
    "\n",
    "In summary, the uniform distribution is a continuous probability distribution that models a random variable that can take on any value in a fixed range, with each value having an equal probability of occurring. A classic example is rolling a fair die, where each outcome has an equal probability of occurring. Another example is the distribution of arrival times of customers at a store during a particular hour, assuming they arrive at random times with no particular pattern."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af02a391-99c1-43a4-8c8b-514a07350c17",
   "metadata": {},
   "source": [
    "# Q8: What is the z score? State the importance of the z score."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7178d42f-2152-4ace-9890-284cc799b150",
   "metadata": {},
   "source": [
    "The z-score, also known as the standard score, is a measure of how many standard deviations an observation or data point is above or below the mean of a population or sample. It is used to standardize and compare values from different datasets that may have different units or scales.\n",
    "\n",
    "The formula for calculating the z-score of a data point x in a population or sample with mean μ and standard deviation σ is:\n",
    "\n",
    "z = (x - μ) / σ\n",
    "\n",
    "A positive z-score indicates that the data point is above the mean, while a negative z-score indicates that it is below the mean. A z-score of 0 indicates that the data point is equal to the mean.\n",
    "\n",
    "The importance of the z-score lies in its ability to provide a standardized measure of how far away an observation or data point is from the mean of the dataset. This enables us to compare values from different datasets that may have different scales and units. It also allows us to compare observations within the same dataset and identify outliers or extreme values that may be far away from the mean.\n",
    "\n",
    "The z-score is often used in hypothesis testing, where it helps to determine whether an observation or data point is statistically significant or not. In statistical analysis, z-scores are often used in conjunction with tables of the standard normal distribution to calculate probabilities and confidence intervals.\n",
    "\n",
    "Overall, the z-score is an important statistical tool that helps to standardize and compare values from different datasets and to identify outliers and extreme values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ac6edb9-1f95-495c-8048-48f5d2fec660",
   "metadata": {},
   "source": [
    "# Q9: What is Central Limit Theorem? State the significance of the Central Limit Theorem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7906139-f32d-4954-bb3c-54a68689c1f4",
   "metadata": {},
   "source": [
    "The Central Limit Theorem (CLT) is a fundamental concept in statistics that states that when independent random variables are added together, their sum tends to follow a normal distribution, regardless of the distribution of the individual variables, as long as the sample size is sufficiently large.\n",
    "\n",
    "In other words, the CLT asserts that the sum or mean of a sufficiently large number of independent and identically distributed random variables will be approximately normally distributed, even if the underlying random variables themselves are not normally distributed.\n",
    "\n",
    "The significance of the Central Limit Theorem lies in its wide-ranging applications in statistical inference and hypothesis testing. The normal distribution is a fundamental probability distribution that is easy to work with mathematically and has many desirable properties, such as being symmetric and unimodal. Therefore, the CLT enables us to use the normal distribution as a model for many real-world phenomena, even if the underlying distributions are unknown or non-normal.\n",
    "\n",
    "For example, the CLT can be used to estimate population parameters from a sample, such as the mean or standard deviation. It is also used in hypothesis testing to determine whether a sample is representative of a larger population.\n",
    "\n",
    "Overall, the Central Limit Theorem is a powerful tool in statistical inference that enables us to make accurate and reliable predictions about population parameters based on sample data, even if the underlying distributions are non-normal."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0610adbe-4122-483e-abba-74a402ebb8b3",
   "metadata": {},
   "source": [
    "# Q10: State the assumptions of the Central Limit Theorem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07754f57-4834-4ac0-a343-2908e3275946",
   "metadata": {},
   "source": [
    "The Central Limit Theorem (CLT) is a fundamental concept in statistics that applies to a wide range of situations. However, there are certain assumptions that must be met for the CLT to hold. These assumptions include:\n",
    "\n",
    "*Independence: The random variables being added together or averaged must be independent of each other.\n",
    "\n",
    "*Sample size: The sample size must be sufficiently large. While there is no strict rule for what constitutes a large sample size, a commonly used guideline is that the sample size should be at least 30.\n",
    "\n",
    "*Identically distributed: The random variables being added together or averaged must have the same distribution.\n",
    "\n",
    "*Finite variance: The variance of the population must be finite. This means that the distribution cannot be too skewed or have extremely heavy tails.\n",
    "\n",
    "*Absence of outliers: There should not be any extreme outliers or influential observations in the data.\n",
    "\n",
    "If these assumptions are met, then the CLT can be applied to estimate population parameters based on sample data, even if the underlying distributions are non-normal. However, if these assumptions are violated, then the CLT may not hold and other methods may need to be used to estimate population parameters."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
